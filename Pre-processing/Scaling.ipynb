{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling refers to putting the values in the same range or same scale so that no variable is dominated by the other.Most of the times dataset will contain features highly varying in magnitudes, units and range.If left alone, these algorithms only take in the magnitude of features neglecting the units. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalability is about handling huge amounts of data and performing a lot of computations in a cost-effective and time-saving way. It Improves the Productivity, Modularity, Minimizing human involvement and reduces the cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of scaling of your data that you may want to consider: normalization and standardization.These can both be achieved using the scikit-learn library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\n",
    "A value is normalized as follows:\n",
    "        y = (x - min) / (max - min)\n",
    "Where the minimum and maximum values pertain to the value x being normalized.\n",
    "Most Commonly used object to normalize the dataset using the scikit-learn is MinMaxScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardizing a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1. It is sometimes referred to as â€œwhitening\".This can be thought of as subtracting the mean value or centering the data. Standardization assumes that your observations fit a Gaussian distribution (bell curve) with a well behaved mean and standard deviation.You can still standardize your data if this expectation is not met, but you may not get reliable results.\n",
    "A value is standardized as follows:\n",
    "        y = (x - mean) / standard_deviation\n",
    "mean = sum(x) / count(x)\n",
    "standard_deviation = sqrt( sum( (x - mean)^2 ) / count(x))\n",
    "\n",
    "Most Commonly used object to standardize the dataset using the scikit-learn is StandardScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us see both the scaling tecniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import followed by Name of library and add a shortcut name 'np'\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyplot is a module in matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the MinMax scaler from sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the StandardScaler scaler from sklearn\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the data from file into a variable 'dataset'\n",
    "dataset = pd.read_csv('Scaling_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151234</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>10000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151235</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>450000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151236</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>78000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151237</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>20000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151238</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>37000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>151239</td>\n",
       "      <td>16</td>\n",
       "      <td>M</td>\n",
       "      <td>49000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>151240</td>\n",
       "      <td>64</td>\n",
       "      <td>F</td>\n",
       "      <td>21000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>151241</td>\n",
       "      <td>83</td>\n",
       "      <td>F</td>\n",
       "      <td>80000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>151242</td>\n",
       "      <td>25</td>\n",
       "      <td>M</td>\n",
       "      <td>35000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>151243</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>90000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>151244</td>\n",
       "      <td>33</td>\n",
       "      <td>M</td>\n",
       "      <td>45000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>151245</td>\n",
       "      <td>46</td>\n",
       "      <td>F</td>\n",
       "      <td>55000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>151246</td>\n",
       "      <td>34</td>\n",
       "      <td>F</td>\n",
       "      <td>65000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>151247</td>\n",
       "      <td>41</td>\n",
       "      <td>M</td>\n",
       "      <td>20000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>151248</td>\n",
       "      <td>39</td>\n",
       "      <td>F</td>\n",
       "      <td>78000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>151249</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>100000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>151250</td>\n",
       "      <td>23</td>\n",
       "      <td>F</td>\n",
       "      <td>9000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>151251</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>80000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>151252</td>\n",
       "      <td>85</td>\n",
       "      <td>F</td>\n",
       "      <td>90000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>151253</td>\n",
       "      <td>24</td>\n",
       "      <td>F</td>\n",
       "      <td>40000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>151254</td>\n",
       "      <td>55</td>\n",
       "      <td>M</td>\n",
       "      <td>120000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>151255</td>\n",
       "      <td>66</td>\n",
       "      <td>M</td>\n",
       "      <td>150000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>151256</td>\n",
       "      <td>38</td>\n",
       "      <td>M</td>\n",
       "      <td>50000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User  Age Gender  Salary Purchase \n",
       "0   151234   23      M   10000         N\n",
       "1   151235   43      F  450000         Y\n",
       "2   151236   54      M   78000         Y\n",
       "3   151237   22      M   20000         N\n",
       "4   151238   19      M   37000         N\n",
       "5   151239   16      M   49000         Y\n",
       "6   151240   64      F   21000         N\n",
       "7   151241   83      F   80000         N\n",
       "8   151242   25      M   35000         N\n",
       "9   151243   64      M   90000         Y\n",
       "10  151244   33      M   45000         N\n",
       "11  151245   46      F   55000         N\n",
       "12  151246   34      F   65000         Y\n",
       "13  151247   41      M   20000         N\n",
       "14  151248   39      F   78000         Y\n",
       "15  151249   54      M  100000         Y\n",
       "16  151250   23      F    9000         N\n",
       "17  151251   57      M   80000         Y\n",
       "18  151252   85      F   90000         Y\n",
       "19  151253   24      F   40000         N\n",
       "20  151254   55      M  120000         Y\n",
       "21  151255   66      M  150000         Y\n",
       "22  151256   38      M   50000         N"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Salary</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151234</td>\n",
       "      <td>23</td>\n",
       "      <td>M</td>\n",
       "      <td>10000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>151235</td>\n",
       "      <td>43</td>\n",
       "      <td>F</td>\n",
       "      <td>450000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>151236</td>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>78000</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>151237</td>\n",
       "      <td>22</td>\n",
       "      <td>M</td>\n",
       "      <td>20000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151238</td>\n",
       "      <td>19</td>\n",
       "      <td>M</td>\n",
       "      <td>37000</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     User  Age Gender  Salary Purchase \n",
       "0  151234   23      M   10000         N\n",
       "1  151235   43      F  450000         Y\n",
       "2  151236   54      M   78000         Y\n",
       "3  151237   22      M   20000         N\n",
       "4  151238   19      M   37000         N"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data set into features and Dependent variables\n",
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, -1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[151234 23 'M' 10000]\n",
      " [151235 43 'F' 450000]\n",
      " [151236 54 'M' 78000]\n",
      " [151237 22 'M' 20000]\n",
      " [151238 19 'M' 37000]\n",
      " [151239 16 'M' 49000]\n",
      " [151240 64 'F' 21000]\n",
      " [151241 83 'F' 80000]\n",
      " [151242 25 'M' 35000]\n",
      " [151243 64 'M' 90000]\n",
      " [151244 33 'M' 45000]\n",
      " [151245 46 'F' 55000]\n",
      " [151246 34 'F' 65000]\n",
      " [151247 41 'M' 20000]\n",
      " [151248 39 'F' 78000]\n",
      " [151249 54 'M' 100000]\n",
      " [151250 23 'F' 9000]\n",
      " [151251 57 'M' 80000]\n",
      " [151252 85 'F' 90000]\n",
      " [151253 24 'F' 40000]\n",
      " [151254 55 'M' 120000]\n",
      " [151255 66 'M' 150000]\n",
      " [151256 38 'M' 50000]]\n"
     ]
    }
   ],
   "source": [
    "print(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['N']\n",
      " ['Y']\n",
      " ['Y']\n",
      " ['N']\n",
      " ['N']\n",
      " ['Y']\n",
      " ['N']\n",
      " ['N']\n",
      " ['N']\n",
      " ['Y']\n",
      " ['N']\n",
      " ['N']\n",
      " ['Y']\n",
      " ['N']\n",
      " ['Y']\n",
      " ['Y']\n",
      " ['N']\n",
      " ['Y']\n",
      " ['Y']\n",
      " ['N']\n",
      " ['Y']\n",
      " ['Y']\n",
      " ['N']]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets. This set will be used for standard scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the standard scalet and pass it to variable 'sc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:, 3:] =sc.fit_transform(X_train[:, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to scale only the columns which have numerical data.\n",
    "In our dataset we observe that the row number 3 'salary' contains datanumerical data with maximum deviation.\n",
    "Let us try to scale the 'Salaries'. Hence the X_train has the column number 3.\n",
    "\n",
    ".fit : Fits the scaler using available training data. As part of this. training data is used to estimate the mean and standard deviation and applying y = (x - mean) / standard_deviation, it calculates the value. This transformation is done to the index no 3 of the training dataset.Tr \n",
    "Transform: Applies the scale to training data. As part of this, ou can use the normalized data to train your model. \n",
    "X_train[:, 3:] : Passing fit_transform to this means, passing the scaled data to the data being used in the current program. This scaled data will be used going forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151247, 41, 'M', -1.0613009845228898],\n",
       "       [151256, 38, 'M', -0.04769892065271404],\n",
       "       [151250, 23, 'F', -1.4329550746086208],\n",
       "       [151242, 25, 'M', -0.5544999525878019],\n",
       "       [151240, 64, 'F', -1.0275142490605507]], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that the index 3 i.e. Salary column is scaled and all the values lie between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[:, 3:] =sc.fit_transform(X_test[:, 3:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we are applying the same scaling to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151245, 46, 'F', -0.6804469389595195],\n",
       "       [151244, 33, 'M', -0.7523251367369335],\n",
       "       [151255, 66, 'M', 0.002395939925913871],\n",
       "       [151248, 39, 'F', -0.5151270840714671],\n",
       "       [151254, 55, 'M', -0.21323865340632822]], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us apply the MinMax scalre and see the data. Before that we need to split the features and DVV into new train and test set. we cannot use the old set as we have already applied the standard scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the MinMax scaler and pass it to variable scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151247, 41, 'M', 20000],\n",
       "       [151256, 38, 'M', 50000],\n",
       "       [151250, 23, 'F', 9000],\n",
       "       [151242, 25, 'M', 35000],\n",
       "       [151240, 64, 'F', 21000],\n",
       "       [151251, 57, 'M', 80000],\n",
       "       [151238, 19, 'M', 37000],\n",
       "       [151236, 54, 'M', 78000],\n",
       "       [151239, 16, 'M', 49000],\n",
       "       [151252, 85, 'F', 90000],\n",
       "       [151243, 64, 'M', 90000],\n",
       "       [151241, 83, 'F', 80000],\n",
       "       [151253, 24, 'F', 40000],\n",
       "       [151237, 22, 'M', 20000],\n",
       "       [151234, 23, 'M', 10000],\n",
       "       [151249, 54, 'M', 100000],\n",
       "       [151246, 34, 'F', 65000]], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train1[:, 3:] = scaler.fit_transform(X_train1[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151247, 41, 'M', 0.12087912087912088],\n",
       "       [151256, 38, 'M', 0.4505494505494505],\n",
       "       [151250, 23, 'F', 0.0],\n",
       "       [151242, 25, 'M', 0.2857142857142857],\n",
       "       [151240, 64, 'F', 0.13186813186813184],\n",
       "       [151251, 57, 'M', 0.7802197802197802],\n",
       "       [151238, 19, 'M', 0.3076923076923077],\n",
       "       [151236, 54, 'M', 0.7582417582417582],\n",
       "       [151239, 16, 'M', 0.43956043956043955],\n",
       "       [151252, 85, 'F', 0.8901098901098901],\n",
       "       [151243, 64, 'M', 0.8901098901098901],\n",
       "       [151241, 83, 'F', 0.7802197802197802],\n",
       "       [151253, 24, 'F', 0.34065934065934067],\n",
       "       [151237, 22, 'M', 0.12087912087912088],\n",
       "       [151234, 23, 'M', 0.010989010989010992],\n",
       "       [151249, 54, 'M', 0.9999999999999999],\n",
       "       [151246, 34, 'F', 0.6153846153846154]], dtype=object)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1[:, 3:] = scaler.fit_transform(X_test1[:, 3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[151245, 46, 'F', 0.024691358024691343],\n",
       "       [151244, 33, 'M', 0.0],\n",
       "       [151255, 66, 'M', 0.25925925925925924],\n",
       "       [151248, 39, 'F', 0.08148148148148147],\n",
       "       [151254, 55, 'M', 0.18518518518518517],\n",
       "       [151235, 43, 'F', 1.0]], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We see here that the scaled values are different than the standard scaler. Every scaler will not provide the same values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is hard to know whether rescaling your data will improve the performance of your algorithms before you apply them.\n",
    "If often can, but not always. A good tip is to create rescaled copies of your dataset and race them against each other\n",
    "using your test harness and a handful of algorithms you want to spot check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data rescaling is an important part of data preparation before applying machine learning algorithms.\n",
    "Normalization is recommended when there is a normal distribution in the features.\n",
    "Standardization works all the time. Standardization would be the ultimate recommendation which will always increase\n",
    "Performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
